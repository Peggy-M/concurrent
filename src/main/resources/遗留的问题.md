

## 遗留的问题

### 阻塞队列当中 ArrayBlockingQueue 的虚假唤醒

~~~ mermaid
sequenceDiagram
    participant A as 线程A(生产者)
    participant Lock as ReentrantLock
    participant Cond as notFull条件
    
    A->>Lock: lock.lockInterruptibly()
    Note right of Lock: 如果锁被占用，A进入同步队列
    Lock-->>A: 获取到锁
    
    A->>Cond: while(count==length)
    Cond->>A: 条件满足，调用await()
    A->>Lock: 释放锁
    A->>Cond: 进入条件队列等待
    
    loop 等待唤醒
        Cond->>A: 保持等待
    end
    
    Cond-->>A: 被signal()唤醒
    A->>Lock: 尝试重新获取锁
    Lock-->>A: 获取锁成功
    A->>Cond: 重新检查while条件
~~~

## 对于LinkedBlockingQueue 与 ArrayBlockingQueue 底层使用的单锁与双锁的区别

### 1. **实现简单性**

- **单锁机制** 的实现更简单直接，代码更容易维护和理解。
- **双锁机制** 需要更复杂的同步策略，比如：
  - 入队和出队操作需要分别获取两把锁。
  - 在扩容或队列状态变更时，可能需要同时获取两把锁（容易导致死锁）。
- `ArrayBlockingQueue` 的设计目标是 **稳定性和可靠性**，而不是极致的性能，因此选择了更保守的实现方式。

------

### 2. **避免死锁风险**

- 在双锁机制下，如果一个线程持有 `putLock` 并尝试获取 `takeLock`，而另一个线程持有 `takeLock` 并尝试获取 `putLock`，就可能发生 **死锁**。
- `ArrayBlockingQueue` 内部可能涉及 `notFull` 和 `notEmpty` 的条件变量，如果使用双锁，需要更复杂的协调机制来避免死锁。
- 单锁机制可以避免这种问题，因为所有操作都是串行化的。

------

### 3. **内存可见性和原子性**

- `ArrayBlockingQueue` 需要保证 `count`（队列元素数量）、`putIndex` 和 `takeIndex` 的 **原子性和可见性**。
- 在单锁机制下，所有变量的修改都在同一把锁的保护下，天然保证了一致性。
- 如果使用双锁机制：
  - `count` 可能需要使用 `volatile` 或 `AtomicInteger`，但仍然可能遇到复合操作的竞争问题（比如 `count++` 需要额外的同步）。
  - `putIndex` 和 `takeIndex` 的更新也需要额外的同步措施，增加了复杂性。

------

### 4. **性能权衡**

- **双锁机制** 理论上可以提高并发性能（因为入队和出队可以同时进行），但实际收益取决于场景：
  - 如果生产者和消费者的速度差异较大（比如生产者远快于消费者），双锁机制可以带来一定的性能提升。
  - 但如果生产者和消费者速度相近，单锁机制的性能可能并不差，甚至由于锁竞争较少（单锁的竞争可能比双锁的细粒度竞争更可控），反而表现更好。
- **单锁机制** 在 **低至中等并发** 下表现良好，而 `ArrayBlockingQueue` 通常用于 **有界队列**（容量固定），高并发场景下可能直接使用 `LinkedBlockingQueue`（它采用了双锁机制）。

------

### 5. **`LinkedBlockingQueue` 使用双锁机制**

- 作为对比，`LinkedBlockingQueue` **采用双锁机制**（`putLock` 和 `takeLock`），因为：
  - 链表结构天然支持更灵活的并发控制（头尾指针可以独立操作）。
  - 它的容量可以是无界的（`Integer.MAX_VALUE`），双锁机制在高并发下能提供更好的吞吐量。
- 但 `ArrayBlockingQueue` 是 **基于数组的**，所有操作都共享同一个数组，双锁机制的优势不明显，反而增加复杂性。

#### LinkedBlockingQueue 当中的生产者唤醒生产者的设计

```java
public boolean offer(E e) {
    //........... 省略部分代码
    if (count.get() < capacity) {
        enqueue(node);
        c = count.getAndIncrement();
        if (c + 1 < capacity)
            //唤醒生产者
            //对于 LinkedBlockingQueue 而言由于读写的锁是分离的，可以在写的情况下存在写的时候
            // 有其他的线程读取，已经完成了消费，那么当前的队列是 null 的可以唤醒之间被阻塞的写线程
            notFull.signal();
    }
}
```

~~~ java
public void put(E e) throws InterruptedException {
    //........... 省略部分代码
    try {
        while (count.get() == capacity) {
            notFull.await();
        }
        enqueue(node);
        c = count.getAndIncrement();
        if (c + 1 < capacity)
            notFull.signal();
    } finally {
        putLock.unlock();
    }
    //........... 省略部分代码
}
~~~



## ThreadPoolExecutor 当中使用 ctl表示着线程池中的2个核心状态的设计目的

### **设计目标**

- **原子性保证**：状态和数量的变更必须作为一个整体操作（避免竞态条件）。
- **性能优化**：减少内存占用和CPU缓存行占用（合并两个变量为一个）。
- **操作高效**：通过位运算快速获取/修改状态或数量。

### **什么是CPU缓存行（Cache Line）？**

现代CPU的缓存是以 **缓存行（Cache Line）** 为单位加载数据的（而不是单个字节或变量）。  
- **典型缓存行大小**：64字节（x86架构）或128字节（某些ARM架构）。  
- **缓存加载规则**：当CPU读取一个变量时，会将该变量所在的整个缓存行加载到L1/L2缓存中。  

**示例：两个变量在内存中的布局**

```java
// 假设有两个独立的AtomicInteger变量：
AtomicInteger state = new AtomicInteger(0);  // 状态
AtomicInteger workerCount = new AtomicInteger(0); // 线程数
```
如果它们的内存地址相邻，可能会落在 **同一个缓存行** 中：
```
| state (4字节) | workerCount (4字节) | 其他数据... |
```
此时，任何对 `state` 或 `workerCount` 的修改，都会导致整个缓存行失效。

### **什么是伪共享（False Sharing）？**

**伪共享** 是指：  
> 多个线程**各自修改不同变量**，但这些变量位于 **同一个缓存行**，导致CPU缓存频繁失效，引发不必要的性能损耗。

### **伪共享的问题**
- **缓存一致性协议（MESI）**：当一个CPU核心修改了缓存行中的数据，其他核心的该缓存行会失效，必须从内存或更高层级缓存重新加载。  
- **性能惩罚**：即使两个线程修改的是不同的变量（如 `state` 和 `workerCount`），由于它们在同一个缓存行，会导致 **不必要的缓存同步**，降低并发性能。

### `ThreadPoolExecutor` 如何用 `ctl` 避免伪共享？

`ThreadPoolExecutor` 使用 **`AtomicInteger ctl` 合并状态和线程数**，本质上是为了：
1. **减少变量数量**：原本需要 `state` + `workerCount` 两个变量，现在只需一个 `ctl`。  
2. **避免伪共享**：  
   - 如果 `state` 和 `workerCount` 分开存储，它们可能会被分配在 **相邻内存**，导致伪共享。  
   - 合并后，`ctl` 单独占用一个缓存行，不会与其他变量冲突。

**优化后的内存布局**

```
| ctl (4字节) | 其他无关变量... |
```
由于 `ctl` 是独立的，修改它不会影响其他变量的缓存行。

###  如何进一步优化缓存友好性？

即使合并了 `ctl`，如果它和其他高频修改的变量（如任务队列的头尾指针）位于同一个缓存行，仍可能有伪共享问题。  
Java 的 `ThreadPoolExecutor` 还采用了 **缓存行填充（Padding）** 技术（在早期版本中更明显）：

```java
// 类似这样的填充（现代JDK可能用 @Contended 注解）
public class ThreadPoolExecutor {
    private volatile int ctl;
    private long p1, p2, p3, p4, p5, p6, p7; // 缓存行填充（避免伪共享）
    private BlockingQueue<Runnable> workQueue;
    // ...
}
```
这样 `ctl` 和 `workQueue` 不会共享同一个缓存行。

